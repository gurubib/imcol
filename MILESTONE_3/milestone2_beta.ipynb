{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 32000\n",
      "Length of validation set: 4000\n",
      "Length of test set: 4000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 40000\n",
    "\n",
    "ids = list(range(0, 70000))\n",
    "random.shuffle(ids)\n",
    "\n",
    "all_id = ids[:dataset_size]\n",
    "\n",
    "valid_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "v_index = int(len(all_id)*(1-valid_split-test_split))\n",
    "t_index = int(len(all_id)*(1-test_split))\n",
    "\n",
    "train_ids = all_id[:v_index]\n",
    "valid_ids = all_id[v_index:t_index]\n",
    "test_ids = all_id[t_index:]\n",
    "\n",
    "print(\"Length of train set: \" + str(len(train_ids)))\n",
    "print(\"Length of validation set: \" + str(len(valid_ids)))\n",
    "print(\"Length of test set: \" + str(len(test_ids)))\n",
    "\n",
    "partition = {'train': train_ids, 'validation': valid_ids, 'test': test_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=10, dim=(256,256,1), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *(256,256,1)), dtype=float)\n",
    "        Y = np.empty((self.batch_size, *(256,256,2)), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img = img_to_array(load_img('C:/Users/lakas/Documents/deeplearning/imcol-master/dataset/' + str(ID) + '.jpg'))\n",
    "            img = 1.0/255*img\n",
    "            img = rgb2lab(img)\n",
    "            \n",
    "            gray = img[:,:,0]\n",
    "            ab = img[:,:,1:] / 128\n",
    "            \n",
    "            # Store sample\n",
    "            X[i,] = gray.reshape((256,256,1))\n",
    "\n",
    "            # Store class\n",
    "            Y[i,] = ab\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience=30\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "class Swish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Swish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish'\n",
    "\n",
    "def swish(x):\n",
    "    # Your activation function specialties here\n",
    "    A = (K.sigmoid(x) * x)\n",
    "    return A\n",
    "\n",
    "get_custom_objects().update({'swish': Swish(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(256, 256, 1,), name='encoder_input')\n",
    "encoder_output = Conv2D(64, (3,3), activation='swish', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='swish', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='swish', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "\n",
    "\n",
    "encoder_output = Conv2D(256, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='swish', padding='same')(encoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='swish', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='swish', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='swish', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=encoder_input, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "640/640 [==============================] - 758s 1s/step - loss: 0.1023 - val_loss: 0.0962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09621, saving model to weights.hdf5\n",
      "Epoch 2/100\n",
      "640/640 [==============================] - 761s 1s/step - loss: 0.0959 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09621 to 0.09544, saving model to weights.hdf5\n",
      "Epoch 3/100\n",
      "640/640 [==============================] - 762s 1s/step - loss: 0.0957 - val_loss: 0.0954\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09544 to 0.09536, saving model to weights.hdf5\n",
      "Epoch 4/100\n",
      "640/640 [==============================] - 756s 1s/step - loss: 0.0952 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09536 to 0.09490, saving model to weights.hdf5\n",
      "Epoch 5/100\n",
      "640/640 [==============================] - 778s 1s/step - loss: 0.0946 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09490 to 0.09470, saving model to weights.hdf5\n",
      "Epoch 6/100\n",
      "640/640 [==============================] - 731s 1s/step - loss: 0.0941 - val_loss: 0.0938\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.09470 to 0.09376, saving model to weights.hdf5\n",
      "Epoch 7/100\n",
      "640/640 [==============================] - 728s 1s/step - loss: 0.0938 - val_loss: 0.0936\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09376 to 0.09357, saving model to weights.hdf5\n",
      "Epoch 8/100\n",
      "640/640 [==============================] - 743s 1s/step - loss: 0.0936 - val_loss: 0.0935\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09357 to 0.09354, saving model to weights.hdf5\n",
      "Epoch 9/100\n",
      "640/640 [==============================] - 738s 1s/step - loss: 0.0933 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09354\n",
      "Epoch 10/100\n",
      "640/640 [==============================] - 729s 1s/step - loss: 0.0928 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09354 to 0.09291, saving model to weights.hdf5\n",
      "Epoch 11/100\n",
      "640/640 [==============================] - 732s 1s/step - loss: 0.0930 - val_loss: 0.0925\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09291 to 0.09247, saving model to weights.hdf5\n",
      "Epoch 12/100\n",
      "640/640 [==============================] - 745s 1s/step - loss: 0.0923 - val_loss: 0.0931\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09247\n",
      "Epoch 13/100\n",
      "640/640 [==============================] - 737s 1s/step - loss: 0.0922 - val_loss: 0.0920\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09247 to 0.09195, saving model to weights.hdf5\n",
      "Epoch 14/100\n",
      "640/640 [==============================] - 728s 1s/step - loss: 0.0915 - val_loss: 0.0911\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09195 to 0.09114, saving model to weights.hdf5\n",
      "Epoch 15/100\n",
      "640/640 [==============================] - 728s 1s/step - loss: 0.0911 - val_loss: 0.0912\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.09114\n",
      "Epoch 16/100\n",
      "640/640 [==============================] - 749s 1s/step - loss: 0.0905 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09114 to 0.09051, saving model to weights.hdf5\n",
      "Epoch 17/100\n",
      "640/640 [==============================] - 760s 1s/step - loss: 0.0898 - val_loss: 0.0907\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09051\n",
      "Epoch 18/100\n",
      "640/640 [==============================] - 761s 1s/step - loss: 0.0891 - val_loss: 0.0905\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09051 to 0.09050, saving model to weights.hdf5\n",
      "Epoch 19/100\n",
      "640/640 [==============================] - 752s 1s/step - loss: 0.0884 - val_loss: 0.0896\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09050 to 0.08962, saving model to weights.hdf5\n",
      "Epoch 20/100\n",
      "640/640 [==============================] - 756s 1s/step - loss: 0.0875 - val_loss: 0.0890\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08962 to 0.08904, saving model to weights.hdf5\n",
      "Epoch 21/100\n",
      "640/640 [==============================] - 749s 1s/step - loss: 0.0866 - val_loss: 0.0892\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08904\n",
      "Epoch 22/100\n",
      "640/640 [==============================] - 775s 1s/step - loss: 0.0857 - val_loss: 0.0895\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08904\n",
      "Epoch 23/100\n",
      "640/640 [==============================] - 772s 1s/step - loss: 0.0840 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08904\n",
      "Epoch 24/100\n",
      "640/640 [==============================] - 760s 1s/step - loss: 0.0823 - val_loss: 0.0888\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.08904 to 0.08881, saving model to weights.hdf5\n",
      "Epoch 25/100\n",
      "640/640 [==============================] - 760s 1s/step - loss: 0.0803 - val_loss: 0.0891\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08881\n",
      "Epoch 26/100\n",
      "640/640 [==============================] - 722s 1s/step - loss: 0.0783 - val_loss: 0.0903\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.08881\n",
      "Epoch 27/100\n",
      "640/640 [==============================] - 716s 1s/step - loss: 0.0759 - val_loss: 0.0907\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08881\n",
      "Epoch 28/100\n",
      "640/640 [==============================] - 717s 1s/step - loss: 0.0739 - val_loss: 0.0909\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08881\n",
      "Epoch 29/100\n",
      "640/640 [==============================] - 726s 1s/step - loss: 0.0718 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08881\n",
      "Epoch 30/100\n",
      "640/640 [==============================] - 716s 1s/step - loss: 0.0698 - val_loss: 0.0917\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08881\n",
      "Epoch 31/100\n",
      "640/640 [==============================] - 717s 1s/step - loss: 0.0677 - val_loss: 0.0915\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.08881\n",
      "Epoch 32/100\n",
      "640/640 [==============================] - 714s 1s/step - loss: 0.0658 - val_loss: 0.0929\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.08881\n",
      "Epoch 33/100\n",
      "640/640 [==============================] - 714s 1s/step - loss: 0.0644 - val_loss: 0.0939\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.08881\n",
      "Epoch 34/100\n",
      "640/640 [==============================] - 721s 1s/step - loss: 0.0627 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.08881\n",
      "Epoch 35/100\n",
      "640/640 [==============================] - 720s 1s/step - loss: 0.0615 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08881\n",
      "Epoch 36/100\n",
      "640/640 [==============================] - 717s 1s/step - loss: 0.0604 - val_loss: 0.0936\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08881\n",
      "Epoch 37/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0593 - val_loss: 0.0939\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08881\n",
      "Epoch 38/100\n",
      "640/640 [==============================] - 721s 1s/step - loss: 0.0582 - val_loss: 0.0942\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08881\n",
      "Epoch 39/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0572 - val_loss: 0.0935\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08881\n",
      "Epoch 40/100\n",
      "640/640 [==============================] - 718s 1s/step - loss: 0.0564 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08881\n",
      "Epoch 41/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0557 - val_loss: 0.0947\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08881\n",
      "Epoch 42/100\n",
      "640/640 [==============================] - 714s 1s/step - loss: 0.0547 - val_loss: 0.0945\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08881\n",
      "Epoch 43/100\n",
      "640/640 [==============================] - 717s 1s/step - loss: 0.0542 - val_loss: 0.0942\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08881\n",
      "Epoch 44/100\n",
      "640/640 [==============================] - 716s 1s/step - loss: 0.0535 - val_loss: 0.0955\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08881\n",
      "Epoch 45/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0531 - val_loss: 0.0956\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08881\n",
      "Epoch 46/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0525 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.08881\n",
      "Epoch 47/100\n",
      "640/640 [==============================] - 714s 1s/step - loss: 0.0519 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08881\n",
      "Epoch 48/100\n",
      "640/640 [==============================] - 715s 1s/step - loss: 0.0513 - val_loss: 0.0956\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08881\n",
      "Epoch 49/100\n",
      "640/640 [==============================] - 722s 1s/step - loss: 0.0508 - val_loss: 0.0950\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08881\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 716s 1s/step - loss: 0.0506 - val_loss: 0.0967\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08881\n",
      "Epoch 51/100\n",
      "640/640 [==============================] - 717s 1s/step - loss: 0.0502 - val_loss: 0.0956\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08881\n",
      "Epoch 52/100\n",
      "640/640 [==============================] - 714s 1s/step - loss: 0.0496 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08881\n",
      "Epoch 53/100\n",
      "640/640 [==============================] - 721s 1s/step - loss: 0.0492 - val_loss: 0.0957\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08881\n",
      "Epoch 54/100\n",
      "640/640 [==============================] - 716s 1s/step - loss: 0.0489 - val_loss: 0.0962\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08881\n",
      "Epoch 00054: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b5bc6d8e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image transformer\n",
    "#datagen = ImageDataGenerator(\n",
    "#        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "#        rotation_range=20,\n",
    "#        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "#batch_size = 10\n",
    "#def image_a_b_gen(batch_size):\n",
    "#    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "#        lab_batch = rgb2lab(batch)\n",
    "#        X_batch = lab_batch[:,:,:,0]\n",
    "#        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "#        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "\n",
    "training_generator = DataGenerator(partition['train'], batch_size=50)\n",
    "valid_generator = DataGenerator(partition['validation'], batch_size=50)\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output/beta_run\")\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "model.fit_generator(training_generator, validation_data=valid_generator,\n",
    "                    epochs=100, steps_per_epoch=len(train_ids)//50, validation_steps=len(valid_ids)//50,\n",
    "                   callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "#Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "#Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "#Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "#Ytest = Ytest / 128\n",
    "#print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lakas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# Change to '/data/images/Test/' to use all the 500 images\n",
    "model = load_model('weights.hdf5')\n",
    "\n",
    "color_me = []\n",
    "for filename in os.listdir('Test/'):\n",
    "\tcolor_me.append(img_to_array(load_img('Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3))\n",
    "\tcur[:,:,0] = color_me[i][:,:,0]\n",
    "\tcur[:,:,1:] = output[i]\n",
    "\timsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 128)       295040    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 64)        73792     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 128, 16)      4624      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, 128, 2)       290       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 2)       0         \n",
      "=================================================================\n",
      "Total params: 6,219,410\n",
      "Trainable params: 6,219,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.772"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "\n",
    "get_model_memory_usage(100, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
