{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 80\n",
      "Length of validation set: 10\n",
      "Length of test set: 10\n"
     ]
    }
   ],
   "source": [
    "all_id = list(range(1000, 1100))\n",
    "\n",
    "valid_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "v_index = int(len(all_id)*(1-valid_split-test_split))\n",
    "t_index = int(len(all_id)*(1-test_split))\n",
    "\n",
    "train_ids = all_id[:v_index]\n",
    "valid_ids = all_id[v_index:t_index]\n",
    "test_ids = all_id[t_index:]\n",
    "\n",
    "print(\"Length of train set: \" + str(len(train_ids)))\n",
    "print(\"Length of validation set: \" + str(len(valid_ids)))\n",
    "print(\"Length of test set: \" + str(len(test_ids)))\n",
    "\n",
    "partition = {'train': train_ids, 'validation': valid_ids, 'test': test_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=10, dim=(256,256,1), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *(256,256,1)), dtype=float)\n",
    "        Y = np.empty((self.batch_size, *(256,256,2)), dtype=float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img = img_to_array(load_img('floydhub_dataset/' + str(ID) + '.jpg'))\n",
    "            img = 1.0/255*img\n",
    "            img = rgb2lab(img)\n",
    "            \n",
    "            gray = img[:,:,0]\n",
    "            ab = img[:,:,1:] / 128\n",
    "            \n",
    "            # Store sample\n",
    "            X[i,] = gray.reshape((256,256,1))\n",
    "\n",
    "            # Store class\n",
    "            Y[i,] = ab\n",
    "\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "#model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(UpSampling2D((2, 2)))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(UpSampling2D((2, 2)))\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "#model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "#model.add(UpSampling2D((2, 2)))\n",
    "#model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(256, 256, 1,), name='encoder_input')\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "model = Model(inputs=encoder_input, outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8/8 [==============================] - 106s 13s/step - loss: 0.9073\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 115s 14s/step - loss: 0.3037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e56fb4080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image transformer\n",
    "#datagen = ImageDataGenerator(\n",
    "#        shear_range=0.2,\n",
    "#        zoom_range=0.2,\n",
    "#        rotation_range=20,\n",
    "#        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "#batch_size = 10\n",
    "#def image_a_b_gen(batch_size):\n",
    "#    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "#        lab_batch = rgb2lab(batch)\n",
    "#        X_batch = lab_batch[:,:,:,0]\n",
    "#        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "#        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "\n",
    "training_generator = DataGenerator(partition['train'], batch_size=10)\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output/beta_run\")\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.fit_generator(training_generator, callbacks=[tensorboard], epochs=2, steps_per_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "#Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "#Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "#Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "#Ytest = Ytest / 128\n",
    "#print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\barni\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# Change to '/data/images/Test/' to use all the 500 images\n",
    "color_me = []\n",
    "for filename in os.listdir('Test/'):\n",
    "\tcolor_me.append(img_to_array(load_img('Test/'+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3))\n",
    "\tcur[:,:,0] = color_me[i][:,:,0]\n",
    "\tcur[:,:,1:] = output[i]\n",
    "\timsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
